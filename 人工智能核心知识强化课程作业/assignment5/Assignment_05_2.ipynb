{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "2_Assignment_05.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjrqMonSaiXm",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swaxJoGJaiXn",
        "colab_type": "text"
      },
      "source": [
        "## 1.复习课上内容， 阅读相应论文。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lisloq3maiXo",
        "colab_type": "text"
      },
      "source": [
        "## 2. 回答以下理论题目"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU-pkdsaaiXp",
        "colab_type": "text"
      },
      "source": [
        "### 2. 1.  What is autoencoder?\n",
        "自编码器是一种把输入的数据重构的神经网络。比如输入的是一张人脸的图片，那么在encoder部分，神经网络首先会把人脸的图片变成一个vector，然后decoder部分是把这个vector再变成一个人脸。Autoencoder也可以是一种特征提取的工具，如果用线性方程，那么作用和PCA很接近；如果用非线性的方程，特征提取的内容可能可以更加丰富。用Autoencoder去提取特征是无监督的降维。\n",
        "\n",
        "Autoencoder 有多种类型，分为：\n",
        "\n",
        "- Undercomplete autoencoders\n",
        "\n",
        "- Sparse autoencoders\n",
        "\n",
        "- Denoising autoencoders\n",
        "\n",
        "- Contractive autoencoders\n",
        "\n",
        "- Stacked denoising autoencoders\n",
        "\n",
        "- Deep autoencoders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VeNb_cxaiXq",
        "colab_type": "text"
      },
      "source": [
        "### 2. 2. What are the differences between greedy search and beam search?\n",
        "贪心搜索会在第一个词生成后，会根据训练好的语言模型挑选出最有可能的第一个词最为第二个。接着根据第二个词选出最有可能出现的第三个词。这种方法可能训练的时候的表现很好，但是最后的呈现出来的效果其实可能一般。\n",
        "\n",
        "比如, Jane is visiting African in September. 和 Jane is going to be visiting Afica in September。这两句话中，第一句话更简洁。然而如果用贪心算法的话，可能因为is 后面更有可能会出现going，最后算法给出的是第二句话。还有如果用贪心算法的话，可能会导致出现的句子不太丰富，当然这取决于应用场景。\n",
        "\n",
        "Beam search在预测的时候，假设词表大小为3，内容为a,b,c。beam size是2，decoder解码的时候：\n",
        "1. 生成第1个词的时候，选择概率最大的2个词，假设为a,c，那么当前的2个序列就是a和c。\n",
        "2. 生成第2个词的时候，将当前序列a和c, 分别与词表中的所有词进行组合，得到新的6个序列aa ab ac ca cb cc，计算每个序列的得分，并选择得分最高的2个序列，作为新的当前序列，假如为 aa cb。\n",
        "3. 不断重复这个过程，直到遇到结束符或者达到最大长度为止。最终输出得分最高的2个序列。\n",
        "\n",
        "所以beam search可以获得前beam size个概率最大的结果。而不是greedy search的单一的最大概率的那个结果。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpRVQ0UnaiXq",
        "colab_type": "text"
      },
      "source": [
        "### 2. 3. What is the intuition of attention mechanism?\n",
        "\n",
        "在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征c再来解码，因此，c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。Attention机制通过在每个时间输入不同的c来解决这个问题。\n",
        "\n",
        "这时，每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用权重值aij来衡量Encoder中第j阶段的hj和解码时第i阶段的相关性。最终Decoder中第i阶段的输入的上下文信息ci就来自于所有hj对aij的加权和。 \n",
        "\n",
        "例如：\n",
        "\n",
        "h1*a11 + h2*a12 + h3*a13 + h4*a14 = c1\n",
        "\n",
        "h1*a21 + h2*a22 + h3*a23 + h4*a24 = c2\n",
        "\n",
        "h1*a31 + h2*a32 + h3*a33 + h4*a34 = c3\n",
        "\n",
        "而这些权重aij是在训练模型的时候得出来的。\n",
        "\n",
        "\n",
        "来源：https://cloud.tencent.com/developer/article/1164493"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpJzRmEIaiXr",
        "colab_type": "text"
      },
      "source": [
        "### 2. 4. What is the disadvantage of word embeding introduced in previous lectures ?\n",
        "word embedding 的缺点是，训练好之后每个单词的表达就固定住了，以后使用的时候，不论新句子上下文单词是什么，这个单词的 Word Embedding 不会跟着上下文场景的变化而改变，如：“ 我喜欢吃苹果 ”，“ 很多人觉得苹果手机很好用 ” 。这两个句子中的苹果是不同的语义，表示不同的对象，没有办法表示出来。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq7KwQ6qaiXs",
        "colab_type": "text"
      },
      "source": [
        "### 2. 5. Briefly describe what is self-attention and what is multi-head attention?\n",
        "\n",
        "### self-attention\n",
        "\n",
        "传统的Attention是基于source端和target端的隐变量（hidden state）计算Attention的，得到的结果是源端的每个词与目标端每个词之间的依赖关系。但Self Attention不同，它分别在source端和target端进行，仅与source input或者target input自身相关的Self Attention，捕捉source端或target端自身的词与词之间的依赖关系；然后再把source端的得到的self Attention加入到target端得到的Attention中，捕捉source端和target端词与词之间的依赖关系。因此，self Attention Attention比传统的Attention mechanism效果要好，主要原因之一是，传统的Attention机制忽略了源端或目标端句子中词与词之间的依赖关系，相对比，self Attention可以不仅可以得到源端与目标端词与词之间的依赖关系，同时还可以有效获取源端或目标端自身词与词之间的依赖关系。\n",
        "\n",
        "来源：https://zhuanlan.zhihu.com/p/79115586\n",
        "\n",
        "### multi-attention\n",
        "\n",
        "Multi-Head Attention相当于h个不同的self-attention的集成（ensemble），在这里我们以h=8 举例说明。Multi-Head Attention的输出分成3步：\n",
        "\n",
        "1. 将数据 X 分别输入到8个self-attention中，得到8个加权后的特征矩阵Zi, i 是1,2,3...,8 。\n",
        "\n",
        "2. 将8个Zi按列拼成一个大的特征矩阵；\n",
        "\n",
        "3. 特征矩阵经过一层全连接后得到输出Z。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sloVEBJxaiXs",
        "colab_type": "text"
      },
      "source": [
        "## 3. 中英文自动翻译模型的构建（使用encoder-decoder模型）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p0WM0x6aiXt",
        "colab_type": "text"
      },
      "source": [
        "![](https://media.geeksforgeeks.org/wp-content/uploads/seq2seq.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaYvyY6paiXt",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 [中英文翻译数据集下载](http://www.manythings.org/anki/)\n",
        "找到Chinese (Mandarin) - English cmn-eng.zip (22075条中英文翻译)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LKJys9E4TLE",
        "colab_type": "code",
        "outputId": "7527b6b8-268f-4fce-ed31-aedbcb5b623c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KjsZNe04ht6",
        "colab_type": "code",
        "outputId": "40421810-47a0-4f6d-8eba-73e0b06a0348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKy84Gry4hxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(n_input, n_output, n_units):\n",
        "    # encoder\n",
        "    encoder_input = Input(shape=(None, n_input))\n",
        "    encoder = LSTM(n_units, return_state=True)\n",
        "    _,encoder_h, encoder_c = encoder(encoder_input)\n",
        "    encoder_state = [encoder_h, encoder_c]\n",
        "    \n",
        "    \n",
        "    # Set up the decoder, using `encoder_states` as initial state.\n",
        "    decoder_input = Input(shape=(None, n_output))\n",
        "    decoder = LSTM(n_units, return_sequences=True, return_state=True)\n",
        "    decoder_output, _, _ = decoder(decoder_input,\n",
        "                                   initial_state=encoder_state)\n",
        "    decoder_dense = Dense(n_output, activation='softmax')\n",
        "    decoder_output = decoder_dense(decoder_output)\n",
        "    \n",
        "    # Define the model \n",
        "    model = Model([encoder_input, decoder_input], decoder_output)\n",
        "    \n",
        "    # inference setup\n",
        "    # encoder\n",
        "    encoder_infer = Model(encoder_input, encoder_state)\n",
        "    \n",
        "    # decoder\n",
        "    decoder_state_input_h = Input(shape=(n_units,))\n",
        "    decoder_state_input_c = Input(shape=(n_units,))    \n",
        "    decoder_state_input = [decoder_state_input_h, decoder_state_input_c] \n",
        "    \n",
        "    decoder_infer_output, decoder_infer_state_h, decoder_infer_state_c = decoder(decoder_input,\n",
        "                                                                                 initial_state=decoder_state_input)\n",
        "    decoder_infer_state = [decoder_infer_state_h, decoder_infer_state_c]\n",
        "    decoder_infer_output = decoder_dense(decoder_infer_output)\n",
        "    \n",
        "    decoder_infer = Model([decoder_input] + decoder_state_input,\n",
        "                          [decoder_infer_output] + decoder_infer_state)\n",
        "    \n",
        "    return model, encoder_infer, decoder_infer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYv1qDVB4hzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_UNITS = 256\n",
        "BATCH_SIZE = 64\n",
        "EPOCH = 50\n",
        "NUM_SAMPLES = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcvOsdpt4h1v",
        "colab_type": "code",
        "outputId": "3ee6b5bc-214d-420b-9f09-10beb1e5908a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "data_path = '/content/drive/My Drive/HCLG/lesson5/cmn-eng/cmn.txt'\n",
        "df = pd.read_table(data_path,header=None).iloc[:NUM_SAMPLES,:,]\n",
        "print(df.shape)\n",
        "df.columns=['targets', 'inputs', 'others']\n",
        "# print(df.head(5))\n",
        "df['targets'] = df['targets'].apply(lambda x: '\\t'+x+'\\n')\n",
        "# print(df.head(5))\n",
        "input_texts = df.inputs.values.tolist()\n",
        "print(type(input_texts))\n",
        "print(input_texts[0:5])\n",
        "\n",
        "target_texts = df.targets.values.tolist()\n",
        "print(target_texts[0:5])\n",
        "\n",
        "# print('df.inputs.unique()')\n",
        "# print(len(df.inputs.unique())) #--> 9578\n",
        "\n",
        "# print('df.inputs.unique().sum()')\n",
        "# print(df.inputs.unique().sum()) # --> Hi.Run.Wait!Hello!I try.I won!Oh no!Cheers!Got it?He ran.Hop in.I qui\n",
        "\n",
        "# print('set(df.inputs.unique().sum())')\n",
        "# print(set(df.inputs.unique().sum())) # --> {'u', 'H', 't', 'M', '7', 'y', 'e', 'K', 'J', 'k ....\n",
        "\n",
        "# print(len(set(df.inputs.unique().sum())))  #--> 72\n",
        "\n",
        "input_characters = sorted(list(set(df.inputs.unique().sum())))\n",
        "print(len(input_characters))\n",
        "\n",
        "\n",
        "target_characters = sorted(list(set(df.targets.unique().sum())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 3)\n",
            "<class 'list'>\n",
            "['嗨。', '你好。', '你用跑的。', '等等！', '等一下！']\n",
            "['\\tHi.\\n', '\\tHi.\\n', '\\tRun.\\n', '\\tWait!\\n', '\\tWait!\\n']\n",
            "2559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7rA89Cd5CbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INUPT_LENGTH = max([len(i) for i in input_texts])\n",
        "OUTPUT_LENGTH = max([len(i) for i in target_texts])\n",
        "INPUT_FEATURE_LENGTH = len(input_characters)\n",
        "# print(INPUT_FEATURE_LENGTH) #--> 72\n",
        "OUTPUT_FEATURE_LENGTH = len(target_characters)\n",
        "# print(OUTPUT_FEATURE_LENGTH)  #--> 2561"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m_lAdmT5CgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NkiM6kNaiXu",
        "colab_type": "text"
      },
      "source": [
        "### 3.2  数据处理：encoder的输入，decoder的输入与输出\n",
        "1，句子转换为one-hot编码     \n",
        "2，LSTM需要的三维输入[n_samples, timestamp, one-hot feature]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwzWOL9j5GcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INUPT_LENGTH = max([len(i) for i in input_texts])\n",
        "OUTPUT_LENGTH = max([len(i) for i in target_texts])\n",
        "INPUT_FEATURE_LENGTH = len(input_characters)\n",
        "# print(INPUT_FEATURE_LENGTH) #--> 72\n",
        "OUTPUT_FEATURE_LENGTH = len(target_characters)\n",
        "# print(OUTPUT_FEATURE_LENGTH)  #--> 2561"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hgso9K5bMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = np.zeros((NUM_SAMPLES, INUPT_LENGTH, INPUT_FEATURE_LENGTH))\n",
        "decoder_input = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))\n",
        "decoder_output = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1KbfLym5Gl4",
        "colab_type": "code",
        "outputId": "cf76e549-8134-4e95-e936-0680884181ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "input_dict = {char:index for index,char in enumerate(input_characters)}\n",
        "print(input_dict)\n",
        "input_dict_reverse = {index:char for index,char in enumerate(input_characters)}\n",
        "target_dict = {char:index for index,char in enumerate(target_characters)}\n",
        "target_dict_reverse = {index:char for index,char in enumerate(target_characters)}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '(': 3, ')': 4, ',': 5, '.': 6, '/': 7, '0': 8, '1': 9, '2': 10, '3': 11, '4': 12, '5': 13, '6': 14, '7': 15, '8': 16, '9': 17, ':': 18, '?': 19, 'A': 20, 'B': 21, 'C': 22, 'D': 23, 'F': 24, 'I': 25, 'J': 26, 'M': 27, 'O': 28, 'P': 29, 'T': 30, 'W': 31, 'a': 32, 'b': 33, 'c': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'o': 44, 'r': 45, 's': 46, 't': 47, 'w': 48, 'y': 49, '\\u200b': 50, '‘': 51, '“': 52, '”': 53, '。': 54, '一': 55, '丁': 56, '七': 57, '万': 58, '丈': 59, '三': 60, '上': 61, '下': 62, '不': 63, '与': 64, '丐': 65, '丑': 66, '专': 67, '且': 68, '世': 69, '业': 70, '东': 71, '丝': 72, '丟': 73, '丢': 74, '两': 75, '严': 76, '並': 77, '丧': 78, '个': 79, '中': 80, '临': 81, '丹': 82, '为': 83, '主': 84, '丽': 85, '举': 86, '久': 87, '么': 88, '义': 89, '之': 90, '乌': 91, '乎': 92, '乏': 93, '乐': 94, '乘': 95, '九': 96, '乞': 97, '也': 98, '习': 99, '乡': 100, '书': 101, '买': 102, '乱': 103, '乳': 104, '乾': 105, '亂': 106, '了': 107, '予': 108, '争': 109, '事': 110, '二': 111, '于': 112, '云': 113, '互': 114, '五': 115, '井': 116, '亚': 117, '些': 118, '亡': 119, '交': 120, '产': 121, '享': 122, '京': 123, '亮': 124, '亲': 125, '人': 126, '什': 127, '仁': 128, '仅': 129, '仇': 130, '今': 131, '介': 132, '仍': 133, '从': 134, '仔': 135, '他': 136, '付': 137, '代': 138, '令': 139, '以': 140, '们': 141, '仰': 142, '件': 143, '价': 144, '任': 145, '份': 146, '仿': 147, '企': 148, '伍': 149, '伏': 150, '伐': 151, '休': 152, '众': 153, '优': 154, '伙': 155, '会': 156, '伞': 157, '伟': 158, '传': 159, '伤': 160, '伦': 161, '伯': 162, '估': 163, '伴': 164, '伸': 165, '似': 166, '但': 167, '位': 168, '低': 169, '住': 170, '佑': 171, '体': 172, '何': 173, '余': 174, '佛': 175, '作': 176, '你': 177, '佣': 178, '佩': 179, '佬': 180, '佳': 181, '使': 182, '來': 183, '例': 184, '侍': 185, '供': 186, '依': 187, '侦': 188, '侧': 189, '侵': 190, '便': 191, '係': 192, '俄': 193, '俊': 194, '保': 195, '信': 196, '修': 197, '俱': 198, '倆': 199, '個': 200, '倍': 201, '們': 202, '倒': 203, '倔': 204, '倖': 205, '候': 206, '倚': 207, '借': 208, '倦': 209, '倫': 210, '债': 211, '值': 212, '假': 213, '偉': 214, '偏': 215, '做': 216, '停': 217, '健': 218, '偶': 219, '偷': 220, '偿': 221, '傑': 222, '傘': 223, '備': 224, '傲': 225, '傳': 226, '傷': 227, '傻': 228, '傾': 229, '像': 230, '僧': 231, '僱': 232, '價': 233, '償': 234, '優': 235, '儿': 236, '允': 237, '元': 238, '兄': 239, '充': 240, '兆': 241, '先': 242, '光': 243, '克': 244, '免': 245, '兒': 246, '兔': 247, '兜': 248, '入': 249, '內': 250, '全': 251, '兩': 252, '八': 253, '公': 254, '六': 255, '兰': 256, '共': 257, '关': 258, '兴': 259, '兵': 260, '其': 261, '具': 262, '典': 263, '养': 264, '兽': 265, '内': 266, '冊': 267, '册': 268, '再': 269, '冒': 270, '写': 271, '军': 272, '冬': 273, '冰': 274, '决': 275, '况': 276, '冷': 277, '冻': 278, '净': 279, '准': 280, '凉': 281, '减': 282, '几': 283, '凡': 284, '凳': 285, '凶': 286, '出': 287, '击': 288, '刀': 289, '分': 290, '切': 291, '划': 292, '列': 293, '则': 294, '刚': 295, '创': 296, '初': 297, '删': 298, '別': 299, '利': 300, '别': 301, '刮': 302, '到': 303, '制': 304, '刷': 305, '刺': 306, '刻': 307, '則': 308, '削': 309, '前': 310, '剔': 311, '剛': 312, '剧': 313, '剩': 314, '剪': 315, '副': 316, '劃': 317, '劇': 318, '劈': 319, '力': 320, '办': 321, '功': 322, '加': 323, '务': 324, '劣': 325, '动': 326, '助': 327, '努': 328, '劫': 329, '劳': 330, '勇': 331, '動': 332, '務': 333, '勝': 334, '勵': 335, '勺': 336, '包': 337, '匆': 338, '匈': 339, '化': 340, '北': 341, '匙': 342, '匱': 343, '匹': 344, '区': 345, '医': 346, '區': 347, '十': 348, '千': 349, '升': 350, '午': 351, '卉': 352, '半': 353, '協': 354, '单': 355, '卖': 356, '南': 357, '博': 358, '卜': 359, '卡': 360, '卧': 361, '卫': 362, '印': 363, '危': 364, '即': 365, '厂': 366, '厅': 367, '历': 368, '厉': 369, '压': 370, '厌': 371, '厕': 372, '厚': 373, '原': 374, '厨': 375, '厭': 376, '厲': 377, '去': 378, '参': 379, '參': 380, '又': 381, '叉': 382, '及': 383, '友': 384, '双': 385, '反': 386, '发': 387, '叔': 388, '取': 389, '受': 390, '变': 391, '叛': 392, '叠': 393, '口': 394, '古': 395, '句': 396, '另': 397, '只': 398, '叫': 399, '叮': 400, '可': 401, '台': 402, '史': 403, '右': 404, '叶': 405, '号': 406, '司': 407, '吃': 408, '各': 409, '合': 410, '吉': 411, '同': 412, '名': 413, '后': 414, '吐': 415, '向': 416, '吓': 417, '吗': 418, '君': 419, '吝': 420, '否': 421, '吧': 422, '含': 423, '听': 424, '启': 425, '吵': 426, '吸': 427, '吹': 428, '吻': 429, '吼': 430, '呀': 431, '呆': 432, '告': 433, '呎': 434, '员': 435, '呢': 436, '周': 437, '味': 438, '呼': 439, '命': 440, '咄': 441, '和': 442, '咎': 443, '咒': 444, '咔': 445, '咖': 446, '咙': 447, '咬': 448, '咱': 449, '咳': 450, '品': 451, '哇': 452, '哈': 453, '响': 454, '哒': 455, '員': 456, '哥': 457, '哦': 458, '哨': 459, '哩': 460, '哪': 461, '哭': 462, '哺': 463, '唇': 464, '唐': 465, '唔': 466, '唬': 467, '售': 468, '唯': 469, '唱': 470, '商': 471, '啊': 472, '問': 473, '啜': 474, '啡': 475, '啤': 476, '啥': 477, '啦': 478, '啬': 479, '喂': 480, '善': 481, '喉': 482, '喊': 483, '喔': 484, '喜': 485, '喝': 486, '喪': 487, '單': 488, '喻': 489, '嗅': 490, '嗎': 491, '嗓': 492, '嗜': 493, '嗝': 494, '嗨': 495, '嗽': 496, '嘗': 497, '嘘': 498, '嘛': 499, '嘲': 500, '嘴': 501, '嘿': 502, '噢': 503, '器': 504, '噩': 505, '噪': 506, '嚇': 507, '嚐': 508, '嚨': 509, '嚮': 510, '嚴': 511, '囚': 512, '四': 513, '回': 514, '因': 515, '团': 516, '园': 517, '困': 518, '固': 519, '国': 520, '图': 521, '圆': 522, '圈': 523, '國': 524, '圍': 525, '園': 526, '圓': 527, '圖': 528, '團': 529, '土': 530, '圣': 531, '在': 532, '地': 533, '场': 534, '圾': 535, '址': 536, '均': 537, '坏': 538, '坐': 539, '块': 540, '坚': 541, '坠': 542, '坡': 543, '坦': 544, '垃': 545, '垄': 546, '型': 547, '垒': 548, '埋': 549, '城': 550, '域': 551, '基': 552, '堂': 553, '堪': 554, '報': 555, '場': 556, '塊': 557, '塔': 558, '塗': 559, '塞': 560, '填': 561, '塵': 562, '境': 563, '墙': 564, '墜': 565, '增': 566, '墨': 567, '墩': 568, '壁': 569, '壓': 570, '壘': 571, '壞': 572, '壤': 573, '士': 574, '壯': 575, '声': 576, '壽': 577, '处': 578, '备': 579, '复': 580, '夏': 581, '夕': 582, '外': 583, '多': 584, '夜': 585, '够': 586, '夠': 587, '夢': 588, '夥': 589, '大': 590, '天': 591, '太': 592, '夫': 593, '夭': 594, '央': 595, '失': 596, '头': 597, '夷': 598, '夸': 599, '夹': 600, '夾': 601, '奇': 602, '奈': 603, '奉': 604, '奋': 605, '奏': 606, '契': 607, '奖': 608, '套': 609, '女': 610, '奴': 611, '奶': 612, '她': 613, '好': 614, '如': 615, '妆': 616, '妇': 617, '妈': 618, '妒': 619, '妙': 620, '妳': 621, '妹': 622, '妻': 623, '姆': 624, '姊': 625, '始': 626, '姐': 627, '姑': 628, '姓': 629, '委': 630, '姨': 631, '姻': 632, '威': 633, '娃': 634, '娘': 635, '娶': 636, '婆': 637, '婉': 638, '婚': 639, '婪': 640, '婴': 641, '媳': 642, '媽': 643, '嫁': 644, '嫉': 645, '嬰': 646, '嬸': 647, '子': 648, '孔': 649, '孕': 650, '字': 651, '存': 652, '季': 653, '孤': 654, '学': 655, '孩': 656, '孫': 657, '學': 658, '宁': 659, '它': 660, '宇': 661, '守': 662, '安': 663, '完': 664, '官': 665, '宙': 666, '定': 667, '宜': 668, '宝': 669, '实': 670, '客': 671, '宣': 672, '室': 673, '害': 674, '家': 675, '容': 676, '宽': 677, '宾': 678, '寂': 679, '寄': 680, '密': 681, '富': 682, '寒': 683, '寓': 684, '寞': 685, '察': 686, '寢': 687, '實': 688, '寧': 689, '審': 690, '寫': 691, '寵': 692, '寸': 693, '对': 694, '寺': 695, '寻': 696, '导': 697, '寿': 698, '封': 699, '射': 700, '将': 701, '將': 702, '專': 703, '尊': 704, '尋': 705, '對': 706, '導': 707, '小': 708, '少': 709, '尔': 710, '尖': 711, '尘': 712, '尝': 713, '尤': 714, '就': 715, '尺': 716, '尼': 717, '尽': 718, '尾': 719, '局': 720, '层': 721, '居': 722, '屈': 723, '屋': 724, '屏': 725, '展': 726, '屜': 727, '属': 728, '屬': 729, '山': 730, '岁': 731, '岛': 732, '岩': 733, '岸': 734, '崎': 735, '巢': 736, '工': 737, '左': 738, '巧': 739, '巨': 740, '巫': 741, '差': 742, '己': 743, '已': 744, '巴': 745, '巾': 746, '市': 747, '布': 748, '帅': 749, '帆': 750, '师': 751, '希': 752, '帐': 753, '帖': 754, '帝': 755, '带': 756, '師': 757, '席': 758, '帮': 759, '帳': 760, '帶': 761, '常': 762, '帽': 763, '幅': 764, '幌': 765, '幕': 766, '幚': 767, '幢': 768, '幣': 769, '幫': 770, '干': 771, '平': 772, '年': 773, '并': 774, '幸': 775, '幹': 776, '幻': 777, '幼': 778, '幽': 779, '幾': 780, '庇': 781, '床': 782, '库': 783, '应': 784, '底': 785, '店': 786, '庙': 787, '府': 788, '庞': 789, '度': 790, '座': 791, '庫': 792, '庭': 793, '康': 794, '廁': 795, '廉': 796, '廚': 797, '廠': 798, '廣': 799, '廳': 800, '建': 801, '开': 802, '弃': 803, '弄': 804, '式': 805, '弓': 806, '引': 807, '弟': 808, '张': 809, '弥': 810, '弱': 811, '張': 812, '強': 813, '弹': 814, '强': 815, '彈': 816, '彎': 817, '归': 818, '当': 819, '形': 820, '彩': 821, '影': 822, '役': 823, '彼': 824, '往': 825, '待': 826, '很': 827, '律': 828, '後': 829, '徑': 830, '得': 831, '從': 832, '微': 833, '德': 834, '心': 835, '必': 836, '忆': 837, '忌': 838, '忍': 839, '志': 840, '忘': 841, '忙': 842, '忠': 843, '快': 844, '念': 845, '忽': 846, '怀': 847, '怎': 848, '怒': 849, '怕': 850, '思': 851, '怠': 852, '急': 853, '性': 854, '怨': 855, '怪': 856, '总': 857, '恋': 858, '恐': 859, '恤': 860, '恥': 861, '恨': 862, '恩': 863, '恭': 864, '息': 865, '恶': 866, '悄': 867, '悅': 868, '悉': 869, '悔': 870, '患': 871, '您': 872, '悲': 873, '情': 874, '惊': 875, '惑': 876, '惕': 877, '惜': 878, '惠': 879, '惡': 880, '惧': 881, '惯': 882, '想': 883, '愉': 884, '意': 885, '愚': 886, '愛': 887, '感': 888, '愤': 889, '愧': 890, '愿': 891, '慈': 892, '慌': 893, '慎': 894, '慕': 895, '慢': 896, '慣': 897, '慧': 898, '慨': 899, '慮': 900, '慰': 901, '慷': 902, '慾': 903, '憂': 904, '憐': 905, '憤': 906, '憶': 907, '憾': 908, '懂': 909, '應': 910, '懒': 911, '懦': 912, '懲': 913, '懷': 914, '戏': 915, '成': 916, '我': 917, '戒': 918, '或': 919, '战': 920, '戚': 921, '戰': 922, '戲': 923, '戳': 924, '戴': 925, '戶': 926, '户': 927, '房': 928, '所': 929, '扇': 930, '手': 931, '才': 932, '扎': 933, '扑': 934, '扒': 935, '打': 936, '扔': 937, '托': 938, '扣': 939, '执': 940, '扫': 941, '扬': 942, '扮': 943, '扯': 944, '扰': 945, '批': 946, '找': 947, '承': 948, '技': 949, '把': 950, '抓': 951, '投': 952, '抗': 953, '折': 954, '抛': 955, '抢': 956, '护': 957, '报': 958, '抨': 959, '披': 960, '抬': 961, '抱': 962, '抵': 963, '抹': 964, '抽': 965, '担': 966, '拉': 967, '拍': 968, '拐': 969, '拒': 970, '拔': 971, '拖': 972, '招': 973, '拜': 974, '拥': 975, '拨': 976, '择': 977, '括': 978, '拯': 979, '拷': 980, '拼': 981, '拾': 982, '拿': 983, '持': 984, '指': 985, '按': 986, '挑': 987, '挖': 988, '挣': 989, '挤': 990, '挥': 991, '挨': 992, '挺': 993, '捉': 994, '捕': 995, '损': 996, '换': 997, '捣': 998, '捲': 999, '掃': 1000, '掉': 1001, '掌': 1002, '排': 1003, '掛': 1004, '採': 1005, '探': 1006, '接': 1007, '控': 1008, '推': 1009, '提': 1010, '插': 1011, '換': 1012, '握': 1013, '援': 1014, '搅': 1015, '搆': 1016, '損': 1017, '搏': 1018, '搞': 1019, '搬': 1020, '搭': 1021, '搶': 1022, '携': 1023, '摇': 1024, '摑': 1025, '摔': 1026, '摘': 1027, '摧': 1028, '摩': 1029, '摸': 1030, '撇': 1031, '撐': 1032, '撒': 1033, '撕': 1034, '撞': 1035, '播': 1036, '撼': 1037, '擁': 1038, '擅': 1039, '擇': 1040, '擊': 1041, '擋': 1042, '操': 1043, '擎': 1044, '擔': 1045, '據': 1046, '擦': 1047, '擺': 1048, '擾': 1049, '攝': 1050, '支': 1051, '收': 1052, '改': 1053, '放': 1054, '政': 1055, '故': 1056, '效': 1057, '敌': 1058, '敏': 1059, '救': 1060, '敗': 1061, '教': 1062, '敢': 1063, '散': 1064, '敦': 1065, '敬': 1066, '数': 1067, '敲': 1068, '整': 1069, '敵': 1070, '數': 1071, '文': 1072, '斗': 1073, '料': 1074, '斤': 1075, '断': 1076, '斯': 1077, '新': 1078, '斷': 1079, '方': 1080, '於': 1081, '施': 1082, '旁': 1083, '旅': 1084, '族': 1085, '旗': 1086, '无': 1087, '既': 1088, '日': 1089, '旦': 1090, '旧': 1091, '早': 1092, '时': 1093, '旷': 1094, '旺': 1095, '昂': 1096, '明': 1097, '易': 1098, '昔': 1099, '星': 1100, '春': 1101, '昨': 1102, '是': 1103, '昵': 1104, '显': 1105, '時': 1106, '晉': 1107, '晒': 1108, '晕': 1109, '晚': 1110, '普': 1111, '景': 1112, '晴': 1113, '智': 1114, '暂': 1115, '暑': 1116, '暖': 1117, '暗': 1118, '暢': 1119, '暱': 1120, '暴': 1121, '曲': 1122, '更': 1123, '書': 1124, '曾': 1125, '替': 1126, '最': 1127, '會': 1128, '月': 1129, '有': 1130, '朋': 1131, '服': 1132, '朗': 1133, '望': 1134, '朝': 1135, '期': 1136, '木': 1137, '未': 1138, '末': 1139, '本': 1140, '札': 1141, '术': 1142, '朵': 1143, '机': 1144, '杀': 1145, '杂': 1146, '权': 1147, '杆': 1148, '杉': 1149, '李': 1150, '材': 1151, '村': 1152, '杜': 1153, '束': 1154, '条': 1155, '来': 1156, '杯': 1157, '東': 1158, '松': 1159, '板': 1160, '极': 1161, '析': 1162, '林': 1163, '果': 1164, '枝': 1165, '枪': 1166, '枯': 1167, '架': 1168, '某': 1169, '染': 1170, '柔': 1171, '柜': 1172, '查': 1173, '柳': 1174, '柴': 1175, '标': 1176, '栋': 1177, '树': 1178, '校': 1179, '样': 1180, '根': 1181, '格': 1182, '案': 1183, '桌': 1184, '桥': 1185, '桶': 1186, '桿': 1187, '條': 1188, '梦': 1189, '梨': 1190, '梯': 1191, '检': 1192, '棄': 1193, '棋': 1194, '棒': 1195, '棚': 1196, '棟': 1197, '森': 1198, '棵': 1199, '椅': 1200, '植': 1201, '楚': 1202, '業': 1203, '極': 1204, '楼': 1205, '概': 1206, '榜': 1207, '榮': 1208, '槍': 1209, '槟': 1210, '樂': 1211, '樓': 1212, '標': 1213, '模': 1214, '樣': 1215, '横': 1216, '樹': 1217, '橄': 1218, '橘': 1219, '橙': 1220, '機': 1221, '橱': 1222, '檢': 1223, '檬': 1224, '檸': 1225, '櫃': 1226, '欄': 1227, '欖': 1228, '欠': 1229, '次': 1230, '欢': 1231, '欣': 1232, '欧': 1233, '欲': 1234, '欺': 1235, '款': 1236, '歇': 1237, '歉': 1238, '歌': 1239, '歐': 1240, '歡': 1241, '止': 1242, '正': 1243, '此': 1244, '步': 1245, '武': 1246, '歧': 1247, '歲': 1248, '歷': 1249, '歸': 1250, '死': 1251, '殃': 1252, '段': 1253, '殺': 1254, '毀': 1255, '毁': 1256, '母': 1257, '每': 1258, '毒': 1259, '比': 1260, '毛': 1261, '毫': 1262, '毯': 1263, '氏': 1264, '民': 1265, '气': 1266, '氣': 1267, '氧': 1268, '水': 1269, '永': 1270, '汁': 1271, '求': 1272, '汉': 1273, '汗': 1274, '汤': 1275, '決': 1276, '汽': 1277, '沉': 1278, '沏': 1279, '沒': 1280, '沙': 1281, '没': 1282, '沮': 1283, '河': 1284, '沸': 1285, '油': 1286, '治': 1287, '沿': 1288, '法': 1289, '泡': 1290, '波': 1291, '泣': 1292, '泥': 1293, '注': 1294, '泪': 1295, '泰': 1296, '泳': 1297, '泼': 1298, '洁': 1299, '洋': 1300, '洗': 1301, '洛': 1302, '洞': 1303, '津': 1304, '洲': 1305, '活': 1306, '洽': 1307, '派': 1308, '流': 1309, '浅': 1310, '浇': 1311, '测': 1312, '济': 1313, '浑': 1314, '浓': 1315, '浩': 1316, '浪': 1317, '浮': 1318, '浴': 1319, '海': 1320, '消': 1321, '涨': 1322, '液': 1323, '涸': 1324, '涼': 1325, '淇': 1326, '淋': 1327, '淚': 1328, '淡': 1329, '淨': 1330, '深': 1331, '混': 1332, '淹': 1333, '添': 1334, '清': 1335, '測': 1336, '港': 1337, '渴': 1338, '游': 1339, '渾': 1340, '湖': 1341, '湯': 1342, '湿': 1343, '源': 1344, '準': 1345, '溜': 1346, '溢': 1347, '溪': 1348, '溫': 1349, '溺': 1350, '滋': 1351, '滑': 1352, '滚': 1353, '满': 1354, '滩': 1355, '滾': 1356, '滿': 1357, '漂': 1358, '漆': 1359, '漏': 1360, '演': 1361, '漢': 1362, '漫': 1363, '漲': 1364, '漸': 1365, '潔': 1366, '潜': 1367, '潤': 1368, '澄': 1369, '澆': 1370, '澡': 1371, '激': 1372, '濒': 1373, '濕': 1374, '瀚': 1375, '灑': 1376, '灣': 1377, '火': 1378, '灭': 1379, '灯': 1380, '灰': 1381, '灵': 1382, '災': 1383, '灾': 1384, '炎': 1385, '炒': 1386, '炸': 1387, '点': 1388, '為': 1389, '烈': 1390, '烏': 1391, '烛': 1392, '烟': 1393, '烤': 1394, '烦': 1395, '烧': 1396, '热': 1397, '烹': 1398, '無': 1399, '然': 1400, '煙': 1401, '煤': 1402, '照': 1403, '煩': 1404, '煮': 1405, '熄': 1406, '熊': 1407, '熟': 1408, '熨': 1409, '熬': 1410, '熱': 1411, '燃': 1412, '燈': 1413, '燒': 1414, '營': 1415, '爆': 1416, '爬': 1417, '爭': 1418, '爱': 1419, '爵': 1420, '父': 1421, '爷': 1422, '爸': 1423, '爺': 1424, '爾': 1425, '牆': 1426, '片': 1427, '版': 1428, '牌': 1429, '牙': 1430, '牛': 1431, '牡': 1432, '牢': 1433, '牧': 1434, '物': 1435, '特': 1436, '犯': 1437, '状': 1438, '狀': 1439, '狂': 1440, '狐': 1441, '狗': 1442, '独': 1443, '狱': 1444, '狸': 1445, '狼': 1446, '猎': 1447, '猜': 1448, '猪': 1449, '猫': 1450, '猴': 1451, '獄': 1452, '獎': 1453, '獨': 1454, '獲': 1455, '獵': 1456, '率': 1457, '王': 1458, '玛': 1459, '玩': 1460, '玫': 1461, '环': 1462, '现': 1463, '玻': 1464, '班': 1465, '現': 1466, '球': 1467, '理': 1468, '琴': 1469, '瑞': 1470, '瑪': 1471, '瑰': 1472, '璃': 1473, '瓜': 1474, '瓦': 1475, '瓶': 1476, '甚': 1477, '甜': 1478, '生': 1479, '產': 1480, '用': 1481, '田': 1482, '由': 1483, '申': 1484, '电': 1485, '男': 1486, '画': 1487, '界': 1488, '畏': 1489, '留': 1490, '畝': 1491, '畢': 1492, '略': 1493, '番': 1494, '畫': 1495, '當': 1496, '疑': 1497, '疗': 1498, '疚': 1499, '疤': 1500, '疯': 1501, '疲': 1502, '疼': 1503, '病': 1504, '症': 1505, '痛': 1506, '痠': 1507, '痴': 1508, '瘋': 1509, '瘦': 1510, '癌': 1511, '癢': 1512, '登': 1513, '發': 1514, '白': 1515, '百': 1516, '皂': 1517, '的': 1518, '皆': 1519, '皮': 1520, '皺': 1521, '盆': 1522, '盈': 1523, '盏': 1524, '盐': 1525, '监': 1526, '盒': 1527, '盔': 1528, '盖': 1529, '盗': 1530, '盘': 1531, '盛': 1532, '盜': 1533, '盟': 1534, '盡': 1535, '監': 1536, '盤': 1537, '目': 1538, '盯': 1539, '盲': 1540, '直': 1541, '相': 1542, '盼': 1543, '眉': 1544, '看': 1545, '真': 1546, '眠': 1547, '眶': 1548, '眼': 1549, '着': 1550, '睁': 1551, '睛': 1552, '睜': 1553, '睡': 1554, '睹': 1555, '瞎': 1556, '瞒': 1557, '瞞': 1558, '瞥': 1559, '瞧': 1560, '瞪': 1561, '瞬': 1562, '瞭': 1563, '矣': 1564, '知': 1565, '矩': 1566, '短': 1567, '矮': 1568, '石': 1569, '矶': 1570, '码': 1571, '砍': 1572, '研': 1573, '砰': 1574, '破': 1575, '砸': 1576, '硬': 1577, '确': 1578, '碌': 1579, '碎': 1580, '碗': 1581, '碟': 1582, '碰': 1583, '確': 1584, '碼': 1585, '磁': 1586, '磅': 1587, '磨': 1588, '示': 1589, '礼': 1590, '社': 1591, '祇': 1592, '祈': 1593, '祖': 1594, '祝': 1595, '神': 1596, '祟': 1597, '票': 1598, '禁': 1599, '禍': 1600, '福': 1601, '禮': 1602, '禱': 1603, '离': 1604, '秀': 1605, '私': 1606, '种': 1607, '科': 1608, '秒': 1609, '秘': 1610, '租': 1611, '积': 1612, '称': 1613, '移': 1614, '稀': 1615, '稅': 1616, '程': 1617, '稍': 1618, '税': 1619, '稚': 1620, '稠': 1621, '種': 1622, '稱': 1623, '稻': 1624, '穌': 1625, '積': 1626, '穫': 1627, '究': 1628, '穷': 1629, '空': 1630, '穿': 1631, '突': 1632, '窍': 1633, '窗': 1634, '窝': 1635, '窩': 1636, '窮': 1637, '立': 1638, '站': 1639, '竟': 1640, '章': 1641, '端': 1642, '競': 1643, '笑': 1644, '笔': 1645, '符': 1646, '笨': 1647, '第': 1648, '筆': 1649, '等': 1650, '筋': 1651, '筑': 1652, '筒': 1653, '答': 1654, '策': 1655, '筝': 1656, '签': 1657, '简': 1658, '箏': 1659, '算': 1660, '管': 1661, '箭': 1662, '箱': 1663, '節': 1664, '篇': 1665, '篮': 1666, '簡': 1667, '簽': 1668, '簿': 1669, '籃': 1670, '籍': 1671, '米': 1672, '类': 1673, '粉': 1674, '粗': 1675, '精': 1676, '糊': 1677, '糕': 1678, '糖': 1679, '糟': 1680, '系': 1681, '紀': 1682, '約': 1683, '紅': 1684, '紋': 1685, '紐': 1686, '純': 1687, '紙': 1688, '素': 1689, '索': 1690, '紧': 1691, '累': 1692, '細': 1693, '紹': 1694, '終': 1695, '結': 1696, '絕': 1697, '絡': 1698, '給': 1699, '絲': 1700, '絶': 1701, '經': 1702, '綠': 1703, '網': 1704, '緊': 1705, '線': 1706, '緝': 1707, '編': 1708, '練': 1709, '總': 1710, '績': 1711, '繁': 1712, '織': 1713, '繩': 1714, '繼': 1715, '續': 1716, '红': 1717, '约': 1718, '级': 1719, '纪': 1720, '纯': 1721, '纸': 1722, '纽': 1723, '练': 1724, '组': 1725, '细': 1726, '织': 1727, '终': 1728, '经': 1729, '绑': 1730, '结': 1731, '给': 1732, '络': 1733, '绝': 1734, '统': 1735, '继': 1736, '绪': 1737, '续': 1738, '绳': 1739, '绵': 1740, '绿': 1741, '缠': 1742, '缸': 1743, '缺': 1744, '网': 1745, '罗': 1746, '罢': 1747, '罪': 1748, '置': 1749, '罰': 1750, '罵': 1751, '羊': 1752, '美': 1753, '羞': 1754, '羡': 1755, '群': 1756, '羨': 1757, '義': 1758, '習': 1759, '翔': 1760, '翰': 1761, '翻': 1762, '翼': 1763, '耀': 1764, '老': 1765, '考': 1766, '者': 1767, '而': 1768, '耍': 1769, '耐': 1770, '耕': 1771, '耗': 1772, '耘': 1773, '耳': 1774, '耶': 1775, '耻': 1776, '聊': 1777, '职': 1778, '联': 1779, '聖': 1780, '聚': 1781, '聞': 1782, '聪': 1783, '聰': 1784, '聲': 1785, '職': 1786, '聽': 1787, '肃': 1788, '肉': 1789, '肚': 1790, '肝': 1791, '股': 1792, '肤': 1793, '肥': 1794, '肩': 1795, '肪': 1796, '肯': 1797, '育': 1798, '肺': 1799, '胃': 1800, '胆': 1801, '背': 1802, '胎': 1803, '胖': 1804, '胜': 1805, '胞': 1806, '胡': 1807, '胳': 1808, '胶': 1809, '能': 1810, '脂': 1811, '脅': 1812, '脆': 1813, '脈': 1814, '脉': 1815, '脏': 1816, '脑': 1817, '脖': 1818, '脚': 1819, '脫': 1820, '脱': 1821, '脸': 1822, '脹': 1823, '脾': 1824, '腆': 1825, '腐': 1826, '腦': 1827, '腳': 1828, '腸': 1829, '腾': 1830, '腿': 1831, '膀': 1832, '膊': 1833, '膏': 1834, '膚': 1835, '膝': 1836, '膽': 1837, '臂': 1838, '臉': 1839, '臟': 1840, '臥': 1841, '自': 1842, '臭': 1843, '至': 1844, '致': 1845, '臺': 1846, '舅': 1847, '與': 1848, '興': 1849, '舉': 1850, '舊': 1851, '舌': 1852, '舒': 1853, '舞': 1854, '般': 1855, '船': 1856, '艘': 1857, '良': 1858, '艰': 1859, '色': 1860, '艺': 1861, '节': 1862, '芙': 1863, '芝': 1864, '花': 1865, '苍': 1866, '苏': 1867, '若': 1868, '苦': 1869, '英': 1870, '苹': 1871, '茄': 1872, '茲': 1873, '茶': 1874, '草': 1875, '荒': 1876, '荣': 1877, '药': 1878, '莉': 1879, '莓': 1880, '莫': 1881, '菜': 1882, '菠': 1883, '華': 1884, '菸': 1885, '萄': 1886, '萝': 1887, '营': 1888, '萨': 1889, '萬': 1890, '落': 1891, '葉': 1892, '著': 1893, '葡': 1894, '董': 1895, '葬': 1896, '葵': 1897, '蒜': 1898, '蒼': 1899, '蓋': 1900, '蓝': 1901, '蓬': 1902, '蔔': 1903, '蔬': 1904, '蔭': 1905, '蔼': 1906, '蕉': 1907, '蕭': 1908, '薩': 1909, '薯': 1910, '藍': 1911, '藏': 1912, '藝': 1913, '藥': 1914, '蘇': 1915, '蘋': 1916, '蘿': 1917, '虎': 1918, '虐': 1919, '虑': 1920, '處': 1921, '虚': 1922, '號': 1923, '虫': 1924, '蚀': 1925, '蚊': 1926, '蛇': 1927, '蛋': 1928, '蛙': 1929, '蛛': 1930, '蛰': 1931, '蜂': 1932, '蜘': 1933, '蜜': 1934, '蝴': 1935, '蝶': 1936, '蠢': 1937, '蠣': 1938, '血': 1939, '行': 1940, '術': 1941, '街': 1942, '衛': 1943, '衣': 1944, '补': 1945, '表': 1946, '衫': 1947, '衬': 1948, '衷': 1949, '袋': 1950, '袖': 1951, '袜': 1952, '被': 1953, '袭': 1954, '裁': 1955, '裂': 1956, '装': 1957, '裏': 1958, '裙': 1959, '補': 1960, '裝': 1961, '裡': 1962, '裤': 1963, '裸': 1964, '裹': 1965, '製': 1966, '複': 1967, '褲': 1968, '襪': 1969, '襯': 1970, '西': 1971, '要': 1972, '見': 1973, '視': 1974, '親': 1975, '覺': 1976, '觀': 1977, '见': 1978, '观': 1979, '规': 1980, '视': 1981, '览': 1982, '觉': 1983, '角': 1984, '解': 1985, '触': 1986, '言': 1987, '訂': 1988, '計': 1989, '訊': 1990, '訓': 1991, '記': 1992, '訝': 1993, '訪': 1994, '設': 1995, '許': 1996, '訴': 1997, '評': 1998, '詞': 1999, '試': 2000, '詩': 2001, '話': 2002, '該': 2003, '誌': 2004, '認': 2005, '誓': 2006, '誕': 2007, '誘': 2008, '語': 2009, '誠': 2010, '誤': 2011, '說': 2012, '誰': 2013, '課': 2014, '調': 2015, '談': 2016, '請': 2017, '諒': 2018, '論': 2019, '諜': 2020, '諾': 2021, '謀': 2022, '謊': 2023, '謎': 2024, '講': 2025, '謝': 2026, '證': 2027, '識': 2028, '警': 2029, '譯': 2030, '議': 2031, '護': 2032, '譽': 2033, '讀': 2034, '變': 2035, '讓': 2036, '计': 2037, '订': 2038, '认': 2039, '讨': 2040, '让': 2041, '训': 2042, '议': 2043, '记': 2044, '讲': 2045, '讶': 2046, '许': 2047, '论': 2048, '设': 2049, '访': 2050, '证': 2051, '评': 2052, '诅': 2053, '识': 2054, '诉': 2055, '词': 2056, '试': 2057, '诗': 2058, '诚': 2059, '话': 2060, '诞': 2061, '该': 2062, '详': 2063, '语': 2064, '误': 2065, '说': 2066, '请': 2067, '诺': 2068, '读': 2069, '课': 2070, '谁': 2071, '调': 2072, '谅': 2073, '谈': 2074, '谎': 2075, '谓': 2076, '谢': 2077, '谣': 2078, '谦': 2079, '谧': 2080, '谨': 2081, '谬': 2082, '谷': 2083, '豆': 2084, '豐': 2085, '豚': 2086, '象': 2087, '豪': 2088, '豫': 2089, '貌': 2090, '貓': 2091, '貝': 2092, '財': 2093, '貨': 2094, '貪': 2095, '責': 2096, '貴': 2097, '買': 2098, '貸': 2099, '費': 2100, '賀': 2101, '賂': 2102, '賄': 2103, '資': 2104, '賞': 2105, '賣': 2106, '賬': 2107, '賭': 2108, '賴': 2109, '賺': 2110, '購': 2111, '賽': 2112, '贊': 2113, '贏': 2114, '贝': 2115, '负': 2116, '财': 2117, '责': 2118, '败': 2119, '账': 2120, '货': 2121, '贫': 2122, '购': 2123, '贵': 2124, '贷': 2125, '费': 2126, '贺': 2127, '资': 2128, '赌': 2129, '赏': 2130, '赖': 2131, '赛': 2132, '赞': 2133, '赢': 2134, '赤': 2135, '走': 2136, '赴': 2137, '赶': 2138, '起': 2139, '趁': 2140, '超': 2141, '越': 2142, '趕': 2143, '趣': 2144, '足': 2145, '趴': 2146, '趾': 2147, '跃': 2148, '跌': 2149, '跑': 2150, '跟': 2151, '跡': 2152, '路': 2153, '跳': 2154, '踏': 2155, '踢': 2156, '踩': 2157, '踪': 2158, '身': 2159, '躲': 2160, '躺': 2161, '車': 2162, '軌': 2163, '軍': 2164, '較': 2165, '載': 2166, '輕': 2167, '輛': 2168, '輟': 2169, '輪': 2170, '輯': 2171, '輸': 2172, '輾': 2173, '轉': 2174, '车': 2175, '轨': 2176, '转': 2177, '轮': 2178, '软': 2179, '轻': 2180, '较': 2181, '辆': 2182, '辈': 2183, '辑': 2184, '输': 2185, '辛': 2186, '辞': 2187, '辣': 2188, '辦': 2189, '辭': 2190, '辰': 2191, '辱': 2192, '農': 2193, '边': 2194, '达': 2195, '迅': 2196, '过': 2197, '迎': 2198, '运': 2199, '近': 2200, '还': 2201, '这': 2202, '进': 2203, '远': 2204, '违': 2205, '连': 2206, '迟': 2207, '迪': 2208, '迫': 2209, '迷': 2210, '迹': 2211, '追': 2212, '退': 2213, '送': 2214, '适': 2215, '逃': 2216, '选': 2217, '透': 2218, '逐': 2219, '递': 2220, '途': 2221, '逗': 2222, '這': 2223, '通': 2224, '逛': 2225, '逝': 2226, '速': 2227, '造': 2228, '連': 2229, '逮': 2230, '週': 2231, '進': 2232, '逻': 2233, '逼': 2234, '遇': 2235, '遊': 2236, '運': 2237, '遍': 2238, '過': 2239, '道': 2240, '達': 2241, '遗': 2242, '遛': 2243, '遞': 2244, '遠': 2245, '遥': 2246, '適': 2247, '遭': 2248, '遲': 2249, '遵': 2250, '選': 2251, '遺': 2252, '避': 2253, '邀': 2254, '還': 2255, '邊': 2256, '那': 2257, '邦': 2258, '邪': 2259, '邮': 2260, '邻': 2261, '郁': 2262, '郎': 2263, '部': 2264, '郵': 2265, '都': 2266, '鄉': 2267, '鄙': 2268, '鄰': 2269, '配': 2270, '酒': 2271, '酣': 2272, '酪': 2273, '酬': 2274, '酷': 2275, '酸': 2276, '醇': 2277, '醉': 2278, '醒': 2279, '醜': 2280, '醫': 2281, '醬': 2282, '醺': 2283, '释': 2284, '釋': 2285, '里': 2286, '重': 2287, '野': 2288, '量': 2289, '金': 2290, '釘': 2291, '釣': 2292, '鈕': 2293, '鈴': 2294, '鉛': 2295, '鉤': 2296, '鉴': 2297, '銀': 2298, '鋒': 2299, '鋪': 2300, '鋼': 2301, '錄': 2302, '錢': 2303, '錯': 2304, '錶': 2305, '鍋': 2306, '鎖': 2307, '鎮': 2308, '鏡': 2309, '鐘': 2310, '鐵': 2311, '鑰': 2312, '鑽': 2313, '钓': 2314, '钟': 2315, '钢': 2316, '钥': 2317, '钱': 2318, '钻': 2319, '铁': 2320, '铃': 2321, '铅': 2322, '铐': 2323, '银': 2324, '锁': 2325, '锋': 2326, '错': 2327, '锤': 2328, '键': 2329, '锯': 2330, '镇': 2331, '镜': 2332, '長': 2333, '长': 2334, '門': 2335, '閉': 2336, '開': 2337, '間': 2338, '閣': 2339, '閱': 2340, '闆': 2341, '闖': 2342, '關': 2343, '门': 2344, '闭': 2345, '问': 2346, '闲': 2347, '间': 2348, '闷': 2349, '闹': 2350, '闻': 2351, '阅': 2352, '队': 2353, '阱': 2354, '防': 2355, '阳': 2356, '阻': 2357, '阿': 2358, '附': 2359, '际': 2360, '陌': 2361, '降': 2362, '限': 2363, '院': 2364, '除': 2365, '险': 2366, '陪': 2367, '陰': 2368, '陶': 2369, '陷': 2370, '陸': 2371, '陽': 2372, '隊': 2373, '随': 2374, '隐': 2375, '隔': 2376, '際': 2377, '障': 2378, '隨': 2379, '險': 2380, '隱': 2381, '隶': 2382, '隸': 2383, '隻': 2384, '难': 2385, '雄': 2386, '雅': 2387, '集': 2388, '雇': 2389, '雙': 2390, '雜': 2391, '雞': 2392, '離': 2393, '難': 2394, '雨': 2395, '雪': 2396, '雲': 2397, '零': 2398, '雷': 2399, '電': 2400, '雾': 2401, '需': 2402, '震': 2403, '霉': 2404, '霧': 2405, '露': 2406, '青': 2407, '靓': 2408, '静': 2409, '靜': 2410, '非': 2411, '靠': 2412, '面': 2413, '靦': 2414, '革': 2415, '靴': 2416, '鞋': 2417, '韩': 2418, '音': 2419, '響': 2420, '頁': 2421, '頂': 2422, '項': 2423, '須': 2424, '預': 2425, '頓': 2426, '領': 2427, '頭': 2428, '顆': 2429, '題': 2430, '顏': 2431, '願': 2432, '類': 2433, '顧': 2434, '顯': 2435, '页': 2436, '顶': 2437, '项': 2438, '顺': 2439, '须': 2440, '顾': 2441, '顿': 2442, '预': 2443, '领': 2444, '颊': 2445, '颗': 2446, '题': 2447, '颜': 2448, '颤': 2449, '風': 2450, '风': 2451, '飛': 2452, '飞': 2453, '食': 2454, '飢': 2455, '飪': 2456, '飯': 2457, '飲': 2458, '飽': 2459, '飾': 2460, '餅': 2461, '養': 2462, '餐': 2463, '餓': 2464, '餘': 2465, '館': 2466, '餵': 2467, '饑': 2468, '饥': 2469, '饭': 2470, '饮': 2471, '饱': 2472, '饶': 2473, '饿': 2474, '馆': 2475, '首': 2476, '香': 2477, '馬': 2478, '駕': 2479, '駛': 2480, '騎': 2481, '騙': 2482, '騰': 2483, '驕': 2484, '驗': 2485, '驚': 2486, '马': 2487, '驳': 2488, '驶': 2489, '驾': 2490, '骂': 2491, '骄': 2492, '验': 2493, '骑': 2494, '骗': 2495, '骚': 2496, '骨': 2497, '髒': 2498, '體': 2499, '高': 2500, '髪': 2501, '髮': 2502, '鬆': 2503, '鬍': 2504, '鬥': 2505, '鬧': 2506, '鬱': 2507, '鬼': 2508, '魂': 2509, '魔': 2510, '魚': 2511, '魯': 2512, '鮮': 2513, '鯨': 2514, '鱼': 2515, '鲜': 2516, '鲸': 2517, '鳄': 2518, '鳥': 2519, '鴉': 2520, '鴕': 2521, '鴨': 2522, '鵡': 2523, '鷹': 2524, '鸚': 2525, '鸟': 2526, '鸡': 2527, '鸵': 2528, '鹽': 2529, '鹿': 2530, '麗': 2531, '麥': 2532, '麦': 2533, '麵': 2534, '麻': 2535, '麼': 2536, '黄': 2537, '黎': 2538, '黑': 2539, '默': 2540, '點': 2541, '鼓': 2542, '鼠': 2543, '鼻': 2544, '齊': 2545, '齒': 2546, '齡': 2547, '齦': 2548, '齿': 2549, '龄': 2550, '龙': 2551, '龟': 2552, '！': 2553, '（': 2554, '）': 2555, '，': 2556, '：': 2557, '？': 2558}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGgLA1M65Go5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for seq_index,seq in enumerate(input_texts):\n",
        "    for char_index, char in enumerate(seq):\n",
        "        encoder_input[seq_index, char_index, input_dict[char]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPTWm5JZaiXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for seq_index,seq in enumerate(target_texts):\n",
        "    for char_index,char in enumerate(seq):\n",
        "        decoder_input[seq_index,char_index, target_dict[char]] = 1.0\n",
        "        if char_index > 0:\n",
        "            decoder_output[seq_index,char_index-1, target_dict[char]] = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN45gguh5izi",
        "colab_type": "code",
        "outputId": "ef33b257-f12f-48f9-ba57-66d0ae26e2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''.join([input_dict_reverse[np.argmax(i)] for i in encoder_input[0] if max(i) !=0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'嗨。'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWbKi8_B5i5A",
        "colab_type": "code",
        "outputId": "a428be4d-92d8-485e-938d-433b2c427c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''.join([target_dict_reverse[np.argmax(i)] for i in decoder_output[0] if max(i) !=0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpX93IZj5i-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_train, encoder_infer, decoder_infer = create_model(INPUT_FEATURE_LENGTH,\n",
        "                                                         OUTPUT_FEATURE_LENGTH,\n",
        "                                                         N_UNITS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUiye8vg5i8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile & run training\n",
        "model_train.compile(optimizer='rmsprop',\n",
        "                    loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOeE-3oW5skL",
        "colab_type": "code",
        "outputId": "cebc6bb2-8b3d-4501-db56-84493a1d54f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model_train.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, 2559)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None, 74)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 2883584     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  338944      input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 74)     19018       lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,241,546\n",
            "Trainable params: 3,241,546\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i95j6U5d5vrx",
        "colab_type": "code",
        "outputId": "6e0710fa-b012-4a96-a327-e233c75611f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "encoder_infer.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, 2559)        0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 256), (None, 256) 2883584   \n",
            "=================================================================\n",
            "Total params: 2,883,584\n",
            "Trainable params: 2,883,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9gytn_15vzs",
        "colab_type": "code",
        "outputId": "6358579f-c0b8-49e7-90cc-55e8a9cb468a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "decoder_infer.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, None, 74)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  338944      input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 74)     19018       lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 357,962\n",
            "Trainable params: 357,962\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61pJPCIu5v2Z",
        "colab_type": "code",
        "outputId": "1d3d4fcb-fe7e-482c-a2b8-29d06d0d847a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "validation_split = 0.2\n",
        "model_train.fit([encoder_input,decoder_input],\n",
        "                decoder_output,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                epochs=EPOCH,\n",
        "                validation_split=validation_split)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/50\n",
            "8000/8000 [==============================] - 66s 8ms/step - loss: 2.0262 - val_loss: 2.5529\n",
            "Epoch 2/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 1.6854 - val_loss: 2.1510\n",
            "Epoch 3/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 1.4857 - val_loss: 2.0075\n",
            "Epoch 4/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 1.3881 - val_loss: 1.9159\n",
            "Epoch 5/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 1.3065 - val_loss: 1.8460\n",
            "Epoch 6/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 1.2292 - val_loss: 1.7459\n",
            "Epoch 7/50\n",
            "8000/8000 [==============================] - 67s 8ms/step - loss: 1.1663 - val_loss: 1.6620\n",
            "Epoch 8/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 1.1180 - val_loss: 1.6078\n",
            "Epoch 9/50\n",
            "8000/8000 [==============================] - 68s 8ms/step - loss: 1.0723 - val_loss: 1.6047\n",
            "Epoch 10/50\n",
            "8000/8000 [==============================] - 68s 8ms/step - loss: 1.0323 - val_loss: 1.5696\n",
            "Epoch 11/50\n",
            "8000/8000 [==============================] - 67s 8ms/step - loss: 0.9959 - val_loss: 1.5187\n",
            "Epoch 12/50\n",
            "8000/8000 [==============================] - 67s 8ms/step - loss: 0.9630 - val_loss: 1.5064\n",
            "Epoch 13/50\n",
            "8000/8000 [==============================] - 67s 8ms/step - loss: 0.9330 - val_loss: 1.4358\n",
            "Epoch 14/50\n",
            "8000/8000 [==============================] - 72s 9ms/step - loss: 0.9035 - val_loss: 1.4263\n",
            "Epoch 15/50\n",
            "8000/8000 [==============================] - 70s 9ms/step - loss: 0.8761 - val_loss: 1.4679\n",
            "Epoch 16/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.8504 - val_loss: 1.4648\n",
            "Epoch 17/50\n",
            "8000/8000 [==============================] - 70s 9ms/step - loss: 0.8261 - val_loss: 1.3927\n",
            "Epoch 18/50\n",
            "8000/8000 [==============================] - 70s 9ms/step - loss: 0.8030 - val_loss: 1.4030\n",
            "Epoch 19/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.7799 - val_loss: 1.3814\n",
            "Epoch 20/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.7578 - val_loss: 1.3700\n",
            "Epoch 21/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.7373 - val_loss: 1.4117\n",
            "Epoch 22/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.7169 - val_loss: 1.3492\n",
            "Epoch 23/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.6993 - val_loss: 1.3556\n",
            "Epoch 24/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.6793 - val_loss: 1.3822\n",
            "Epoch 25/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.6610 - val_loss: 1.3888\n",
            "Epoch 26/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.6429 - val_loss: 1.4089\n",
            "Epoch 27/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.6247 - val_loss: 1.4029\n",
            "Epoch 28/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.6084 - val_loss: 1.3923\n",
            "Epoch 29/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.5918 - val_loss: 1.3943\n",
            "Epoch 30/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.5760 - val_loss: 1.4308\n",
            "Epoch 31/50\n",
            "8000/8000 [==============================] - 68s 8ms/step - loss: 0.5594 - val_loss: 1.4249\n",
            "Epoch 32/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.5436 - val_loss: 1.4688\n",
            "Epoch 33/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.5282 - val_loss: 1.4936\n",
            "Epoch 34/50\n",
            "8000/8000 [==============================] - 68s 9ms/step - loss: 0.5146 - val_loss: 1.4777\n",
            "Epoch 35/50\n",
            "8000/8000 [==============================] - 69s 9ms/step - loss: 0.4989 - val_loss: 1.5150\n",
            "Epoch 36/50\n",
            "8000/8000 [==============================] - 72s 9ms/step - loss: 0.4847 - val_loss: 1.4860\n",
            "Epoch 37/50\n",
            "8000/8000 [==============================] - 72s 9ms/step - loss: 0.4717 - val_loss: 1.4997\n",
            "8000/8000 [==============================] - 72s 9ms/step - loss: 0.4717 - val_loss: 1.4997\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "8000/8000 [==============================] - 74s 9ms/step - loss: 0.4575 - val_loss: 1.5289\n",
            "8000/8000 [==============================] - 74s 9ms/step - loss: 0.4575 - val_loss: 1.5289\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "8000/8000 [==============================] - 76s 9ms/step - loss: 0.4445 - val_loss: 1.5345\n",
            "8000/8000 [==============================] - 76s 9ms/step - loss: 0.4445 - val_loss: 1.5345\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "8000/8000 [==============================] - 80s 10ms/step - loss: 0.4317 - val_loss: 1.6017\n",
            "8000/8000 [==============================] - 80s 10ms/step - loss: 0.4317 - val_loss: 1.6017\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "8000/8000 [==============================] - 75s 9ms/step - loss: 0.4197 - val_loss: 1.6169\n",
            "8000/8000 [==============================] - 75s 9ms/step - loss: 0.4197 - val_loss: 1.6169\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "8000/8000 [==============================] - 75s 9ms/step - loss: 0.4062 - val_loss: 1.6216\n",
            "8000/8000 [==============================] - 75s 9ms/step - loss: 0.4062 - val_loss: 1.6216\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "8000/8000 [==============================] - 73s 9ms/step - loss: 0.3956 - val_loss: 1.6476\n",
            "8000/8000 [==============================] - 73s 9ms/step - loss: 0.3956 - val_loss: 1.6476\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "8000/8000 [==============================] - 76s 10ms/step - loss: 0.3829 - val_loss: 1.6406\n",
            "8000/8000 [==============================] - 76s 10ms/step - loss: 0.3829 - val_loss: 1.6406\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "8000/8000 [==============================] - 74s 9ms/step - loss: 0.3720 - val_loss: 1.6703\n",
            "8000/8000 [==============================] - 74s 9ms/step - loss: 0.3720 - val_loss: 1.6703\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "8000/8000 [==============================] - 73s 9ms/step - loss: 0.3609 - val_loss: 1.6703\n",
            "8000/8000 [==============================] - 73s 9ms/step - loss: 0.3609 - val_loss: 1.6703\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "8000/8000 [==============================] - 76s 9ms/step - loss: 0.3500 - val_loss: 1.6904\n",
            "8000/8000 [==============================] - 76s 9ms/step - loss: 0.3500 - val_loss: 1.6904\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "8000/8000 [==============================] - 78s 10ms/step - loss: 0.3406 - val_loss: 1.7543\n",
            "8000/8000 [==============================] - 78s 10ms/step - loss: 0.3406 - val_loss: 1.7543\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "8000/8000 [==============================] - 79s 10ms/step - loss: 0.3299 - val_loss: 1.7623\n",
            "8000/8000 [==============================] - 79s 10ms/step - loss: 0.3299 - val_loss: 1.7623\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "8000/8000 [==============================] - 77s 10ms/step - loss: 0.3205 - val_loss: 1.7725\n",
            "8000/8000 [==============================] - 77s 10ms/step - loss: 0.3205 - val_loss: 1.7725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa0e27f7da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa0e27f7da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58HlxYGUaiXx",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 encoder-decoder模型的搭建\n",
        "1，模型训练    \n",
        "2，模型推理     \n",
        "3，模型预测，展示结果   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPKmzQB7aiXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_chinese(source,encoder_inference, decoder_inference, n_steps, features):\n",
        "    state = encoder_inference.predict(source)\n",
        "    predict_seq = np.zeros((1,1,features))\n",
        "    predict_seq[0,0,target_dict['\\t']] = 1\n",
        "\n",
        "    output = ''\n",
        "\n",
        "    for i in range(n_steps): # n_steps为句子最大长度\n",
        "        yhat,h,c = decoder_inference.predict([predict_seq]+state)\n",
        "        char_index = np.argmax(yhat[0,-1,:])\n",
        "        char = target_dict_reverse[char_index]\n",
        "        output += char\n",
        "        state = [h,c]\n",
        "        predict_seq = np.zeros((1,1,features))\n",
        "        predict_seq[0,0,char_index] = 1\n",
        "        if char == '\\n':\n",
        "            break\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwM9DjKq6AVZ",
        "colab_type": "code",
        "outputId": "cdbd580e-d18c-4d3e-a7fc-84fa9e1012e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(1000,1100):\n",
        "    test = encoder_input[i:i+1,:,:] \n",
        "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
        "    print(input_texts[i])\n",
        "    print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "停止发牢骚吧。\n",
            "Stom gremsing.\n",
            "\n",
            "停止抵抗！\n",
            "Stop rellivet you ligs.\n",
            "\n",
            "夏天过去了。\n",
            "Semes are mather.\n",
            "\n",
            "你可以慢慢来。\n",
            "You can come in.\n",
            "\n",
            "慢慢来。\n",
            "Take atalle.\n",
            "\n",
            "那样是错的。\n",
            "That's a brother faim.\n",
            "\n",
            "那是一個恥辱。\n",
            "That's a bit day aroum.\n",
            "\n",
            "那符合逻辑。\n",
            "That's time.\n",
            "\n",
            "停止发牢骚吧。\n",
            "Stom gremsing.\n",
            "\n",
            "停止抵抗！\n",
            "Stop rellivet you ligs.\n",
            "\n",
            "夏天过去了。\n",
            "Semes are mather.\n",
            "\n",
            "你可以慢慢来。\n",
            "You can come in.\n",
            "\n",
            "慢慢来。\n",
            "Take atalle.\n",
            "\n",
            "那样是错的。\n",
            "That's a brother faim.\n",
            "\n",
            "那是一個恥辱。\n",
            "That's a bit day aroum.\n",
            "\n",
            "那符合逻辑。\n",
            "That's time.\n",
            "\n",
            "那是我的大衣。\n",
            "That's a breathe's hood.\n",
            "\n",
            "那是完美的。\n",
            "That's a good ideat.\n",
            "\n",
            "太可惜了！\n",
            "That's too bad.\n",
            "\n",
            "多遗憾啊！\n",
            "That's too bad.\n",
            "\n",
            "那太糟糕了。\n",
            "It's a sick tomorrow.\n",
            "\n",
            "鳥兒歌唱。\n",
            "Birds sing.\n",
            "\n",
            "旗子升起了。\n",
            "The ste is too saccer.\n",
            "\n",
            "電話正在響。\n",
            "The pen is for for this.\n",
            "\n",
            "那是我的大衣。\n",
            "That's a breathe's hood.\n",
            "\n",
            "那是完美的。\n",
            "That's a good ideat.\n",
            "\n",
            "太可惜了！\n",
            "That's too bad.\n",
            "\n",
            "多遗憾啊！\n",
            "That's too bad.\n",
            "\n",
            "那太糟糕了。\n",
            "It's a sick tomorrow.\n",
            "\n",
            "鳥兒歌唱。\n",
            "Birds sing.\n",
            "\n",
            "旗子升起了。\n",
            "The ste is too saccer.\n",
            "\n",
            "電話正在響。\n",
            "The pen is for for this.\n",
            "\n",
            "他們目光相接。\n",
            "Their eys are her aroum.\n",
            "\n",
            "這些是筆。\n",
            "These are thene fool.\n",
            "\n",
            "他們恨湯姆。\n",
            "They hated my car.\n",
            "\n",
            "他們有工作。\n",
            "They are very good news.\n",
            "\n",
            "他們讓我走。\n",
            "They leve the doore.\n",
            "\n",
            "他们喜欢那个\n",
            "They love that.\n",
            "\n",
            "他们信任汤姆。\n",
            "They hated me hast.\n",
            "\n",
            "他們想要更多。\n",
            "They want more to drathe.\n",
            "\n",
            "他們目光相接。\n",
            "Their eys are her aroum.\n",
            "\n",
            "這些是筆。\n",
            "These are thene fool.\n",
            "\n",
            "他們恨湯姆。\n",
            "They hated my car.\n",
            "\n",
            "他們有工作。\n",
            "They are very good news.\n",
            "\n",
            "他們讓我走。\n",
            "They leve the doore.\n",
            "\n",
            "他们喜欢那个\n",
            "They love that.\n",
            "\n",
            "他们信任汤姆。\n",
            "They hated me hast.\n",
            "\n",
            "他們想要更多。\n",
            "They want more to drathe.\n",
            "\n",
            "他們想要這個。\n",
            "They want me tile.\n",
            "\n",
            "他们不错。\n",
            "They were going.\n",
            "\n",
            "这是一本书。\n",
            "This is a pencil.\n",
            "\n",
            "那是我的包。\n",
            "This is a strange tear.\n",
            "\n",
            "湯姆能改變。\n",
            "Tom can can that formon.\n",
            "\n",
            "汤姆不会游泳。\n",
            "Tom don't want to sick.\n",
            "\n",
            "湯姆有個計畫。\n",
            "Tom has a good feaming.\n",
            "\n",
            "他們想要這個。\n",
            "They want me tile.\n",
            "\n",
            "他们不错。\n",
            "They were going.\n",
            "\n",
            "这是一本书。\n",
            "This is a pencil.\n",
            "\n",
            "那是我的包。\n",
            "This is a strange tear.\n",
            "\n",
            "湯姆能改變。\n",
            "Tom can can that formon.\n",
            "\n",
            "汤姆不会游泳。\n",
            "Tom don't want to sick.\n",
            "\n",
            "湯姆有個計畫。\n",
            "Tom has a good feaming.\n",
            "\n",
            "汤姆是个拉比。\n",
            "Tom is a good money.\n",
            "\n",
            "汤姆不傻。\n",
            "Tom isn't a hero.\n",
            "\n",
            "汤姆不傻。\n",
            "Tom isn't a hero.\n",
            "\n",
            "湯姆看起來很蒼白。\n",
            "Tom let uppet trove.\n",
            "\n",
            "汤姆喜欢狗。\n",
            "Tom lives to hell.\n",
            "\n",
            "汤姆脸红了。\n",
            "Tom broke the proble.\n",
            "\n",
            "湯姆走了出去。\n",
            "Tom was wearte for end.\n",
            "\n",
            "汤姆当时在哭。\n",
            "Tom was very saccestine.\n",
            "\n",
            "汤姆是个拉比。\n",
            "Tom is a good money.\n",
            "\n",
            "汤姆不傻。\n",
            "Tom isn't a hero.\n",
            "\n",
            "汤姆不傻。\n",
            "Tom isn't a hero.\n",
            "\n",
            "湯姆看起來很蒼白。\n",
            "Tom let uppet trove.\n",
            "\n",
            "汤姆喜欢狗。\n",
            "Tom lives to hell.\n",
            "\n",
            "汤姆脸红了。\n",
            "Tom broke the proble.\n",
            "\n",
            "湯姆走了出去。\n",
            "Tom was wearte for end.\n",
            "\n",
            "汤姆当时在哭。\n",
            "Tom was very saccestine.\n",
            "\n",
            "湯姆不會停。\n",
            "Tom won't go to sted.\n",
            "\n",
            "汤姆无所畏惧。\n",
            "Tom is a planent over.\n",
            "\n",
            "汤姆在笑。\n",
            "Tom has gone of crieder.\n",
            "\n",
            "汤姆兴奋不已。\n",
            "Tom is alreay as idilat.\n",
            "\n",
            "开电视。\n",
            "Turn on the radio.\n",
            "\n",
            "把电视声音调大点儿。\n",
            "Turn up the TV.\n",
            "\n",
            "汤姆睡着了吗？\n",
            "Does Tom have a gialftoen?\n",
            "\n",
            "湯姆不會停。\n",
            "Tom won't go to sted.\n",
            "\n",
            "汤姆无所畏惧。\n",
            "Tom is a planent over.\n",
            "\n",
            "汤姆在笑。\n",
            "Tom has gone of crieder.\n",
            "\n",
            "汤姆兴奋不已。\n",
            "Tom is alreay as idilat.\n",
            "\n",
            "开电视。\n",
            "Turn on the radio.\n",
            "\n",
            "把电视声音调大点儿。\n",
            "Turn up the TV.\n",
            "\n",
            "汤姆睡着了吗？\n",
            "Does Tom have a gialftoen?\n",
            "\n",
            "洗您的脚。\n",
            "Wash your feet.\n",
            "\n",
            "洗你的脚。\n",
            "Wash your feet.\n",
            "\n",
            "自己当心啊。\n",
            "Watch yourself.\n",
            "\n",
            "我們原諒你。\n",
            "We have to stay here.\n",
            "\n",
            "我們誰也不認識。\n",
            "We knew no one.\n",
            "\n",
            "我們需要英雄。\n",
            "We need a harry.\n",
            "\n",
            "我们学习音乐。\n",
            "We love my car.\n",
            "\n",
            "我們被偷了。\n",
            "We'll be back.\n",
            "\n",
            "洗您的脚。\n",
            "Wash your feet.\n",
            "\n",
            "洗你的脚。\n",
            "Wash your feet.\n",
            "\n",
            "自己当心啊。\n",
            "Watch yourself.\n",
            "\n",
            "我們原諒你。\n",
            "We have to stay here.\n",
            "\n",
            "我們誰也不認識。\n",
            "We knew no one.\n",
            "\n",
            "我們需要英雄。\n",
            "We need a harry.\n",
            "\n",
            "我们学习音乐。\n",
            "We love my car.\n",
            "\n",
            "我們被偷了。\n",
            "We'll be back.\n",
            "\n",
            "我们要继续下去。\n",
            "We want to go to eat.\n",
            "\n",
            "我們是個家庭。\n",
            "We're all at right.\n",
            "\n",
            "我们没迟到。\n",
            "We have no come.\n",
            "\n",
            "好吧，我們走吧。\n",
            "Let's go some soccer.\n",
            "\n",
            "你是对的吗？\n",
            "Are you serious?\n",
            "\n",
            "你們呢？\n",
            "What about you?\n",
            "\n",
            "您呢？\n",
            "How about you?\n",
            "\n",
            "你的職業是什麼?\n",
            "What do you do?\n",
            "\n",
            "我们要继续下去。\n",
            "We want to go to eat.\n",
            "\n",
            "我們是個家庭。\n",
            "We're all at right.\n",
            "\n",
            "我们没迟到。\n",
            "We have no come.\n",
            "\n",
            "好吧，我們走吧。\n",
            "Let's go some soccer.\n",
            "\n",
            "你是对的吗？\n",
            "Are you serious?\n",
            "\n",
            "你們呢？\n",
            "What about you?\n",
            "\n",
            "您呢？\n",
            "How about you?\n",
            "\n",
            "你的職業是什麼?\n",
            "What do you do?\n",
            "\n",
            "她做什么工作？\n",
            "What did she say?\n",
            "\n",
            "我们去哪儿？\n",
            "Where do we go?\n",
            "\n",
            "之前你在哪里？\n",
            "Where is your house?\n",
            "\n",
            "那家伙是谁？\n",
            "Who is that too?\n",
            "\n",
            "那男人是谁？\n",
            "Who is that smome?\n",
            "\n",
            "你問這個幹什麼?\n",
            "Why do you mad?\n",
            "\n",
            "为什么他在这儿？\n",
            "Why is he here?\n",
            "\n",
            "擦擦你的眼睛。\n",
            "Tute your has soun.\n",
            "\n",
            "她做什么工作？\n",
            "What did she say?\n",
            "\n",
            "我们去哪儿？\n",
            "Where do we go?\n",
            "\n",
            "之前你在哪里？\n",
            "Where is your house?\n",
            "\n",
            "那家伙是谁？\n",
            "Who is that too?\n",
            "\n",
            "那男人是谁？\n",
            "Who is that smome?\n",
            "\n",
            "你問這個幹什麼?\n",
            "Why do you mad?\n",
            "\n",
            "为什么他在这儿？\n",
            "Why is he here?\n",
            "\n",
            "擦擦你的眼睛。\n",
            "Tute your has soun.\n",
            "\n",
            "是的，我知道。\n",
            "It's really better.\n",
            "\n",
            "是的，當然。\n",
            "It's raining lust.\n",
            "\n",
            "你看起來很無聊。\n",
            "You look very an aguit.\n",
            "\n",
            "你看起来很紧张。\n",
            "You should learn here.\n",
            "\n",
            "你看起來很疲倦。\n",
            "You look very allead.\n",
            "\n",
            "你看起来很困了。\n",
            "You look very angry.\n",
            "\n",
            "你必須去做。\n",
            "You must do no help.\n",
            "\n",
            "你會愛它。\n",
            "You'll love to go.\n",
            "\n",
            "是的，我知道。\n",
            "It's really better.\n",
            "\n",
            "是的，當然。\n",
            "It's raining lust.\n",
            "\n",
            "你看起來很無聊。\n",
            "You look very an aguit.\n",
            "\n",
            "你看起来很紧张。\n",
            "You should learn here.\n",
            "\n",
            "你看起來很疲倦。\n",
            "You look very allead.\n",
            "\n",
            "你看起来很困了。\n",
            "You look very angry.\n",
            "\n",
            "你必須去做。\n",
            "You must do no help.\n",
            "\n",
            "你會愛它。\n",
            "You'll love to go.\n",
            "\n",
            "你開玩笑吧！\n",
            "You're kidding!\n",
            "\n",
            "您不必感谢我。\n",
            "You have to leave.\n",
            "\n",
            "男人应该工作。\n",
            "Man can do one of sust.\n",
            "\n",
            "你們是朋友嗎？\n",
            "Are you grod ind?\n",
            "\n",
            "你在开玩笑吗？\n",
            "Do you have a car?\n",
            "\n",
            "你有18歲了嗎？\n",
            "Are you still like juice?\n",
            "\n",
            "你是认真的吗？\n",
            "Are you still colfee?\n",
            "\n",
            "你開玩笑吧！\n",
            "You're kidding!\n",
            "\n",
            "您不必感谢我。\n",
            "You have to leave.\n",
            "\n",
            "男人应该工作。\n",
            "Man can do one of sust.\n",
            "\n",
            "你們是朋友嗎？\n",
            "Are you grod ind?\n",
            "\n",
            "你在开玩笑吗？\n",
            "Do you have a car?\n",
            "\n",
            "你有18歲了嗎？\n",
            "Are you still like juice?\n",
            "\n",
            "你是认真的吗？\n",
            "Are you still colfee?\n",
            "\n",
            "你渴吗？\n",
            "Are you still colf?\n",
            "\n",
            "球是圆的。\n",
            "Barls are hirs.\n",
            "\n",
            "为我感到高兴吧。\n",
            "Come is not truely took.\n",
            "\n",
            "规矩点。\n",
            "Beake up!\n",
            "\n",
            "黑色很衬你。\n",
            "Beccorricle is beread.\n",
            "\n",
            "烧一点水。\n",
            "Come on.\n",
            "\n",
            "叫警察！\n",
            "Call the police!\n",
            "\n",
            "报警！\n",
            "Call the police.\n",
            "\n",
            "你渴吗？\n",
            "Are you still colf?\n",
            "\n",
            "球是圆的。\n",
            "Barls are hirs.\n",
            "\n",
            "为我感到高兴吧。\n",
            "Come is not truely took.\n",
            "\n",
            "规矩点。\n",
            "Beake up!\n",
            "\n",
            "黑色很衬你。\n",
            "Beccorricle is beread.\n",
            "\n",
            "烧一点水。\n",
            "Come on.\n",
            "\n",
            "叫警察！\n",
            "Call the police!\n",
            "\n",
            "报警！\n",
            "Call the police.\n",
            "\n",
            "报警！\n",
            "Call the police.\n",
            "\n",
            "你能找到它嗎？\n",
            "Can you speak English?\n",
            "\n",
            "你能幫我嗎？\n",
            "Can you help me?\n",
            "\n",
            "您能帮我吗？\n",
            "Can you help me?\n",
            "\n",
            "你能幫我們嗎？\n",
            "Can you help me?\n",
            "\n",
            "清掃你的房間。\n",
            "Clean your room.\n",
            "\n",
            "打扫一下你的房间。\n",
            "Clean your room.\n",
            "\n",
            "报警！\n",
            "Call the police.\n",
            "\n",
            "你能找到它嗎？\n",
            "Can you speak English?\n",
            "\n",
            "你能幫我嗎？\n",
            "Can you help me?\n",
            "\n",
            "您能帮我吗？\n",
            "Can you help me?\n",
            "\n",
            "你能幫我們嗎？\n",
            "Can you help me?\n",
            "\n",
            "清掃你的房間。\n",
            "Clean your room.\n",
            "\n",
            "打扫一下你的房间。\n",
            "Clean your room.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz8VO20saiX0",
        "colab_type": "text"
      },
      "source": [
        "![](https://stickershop.line-scdn.net/stickershop/v1/product/3624648/LINEStorePC/main.png;compress=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3MzZtohfr3c",
        "colab_type": "text"
      },
      "source": [
        "### 以上是从中文到英文的翻译过程，过程的结果不是很好，参数有待调整。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqZyoH2Hf08x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}